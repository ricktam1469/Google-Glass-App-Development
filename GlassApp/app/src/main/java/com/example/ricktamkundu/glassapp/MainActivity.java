package com.example.ricktamkundu.glassapp;

import com.google.android.glass.app.Card;
import com.google.android.glass.media.Sounds;
import com.google.android.glass.widget.CardBuilder;
import com.google.android.glass.widget.CardScrollAdapter;
import com.google.android.glass.widget.CardScrollView;
import com.google.gson.JsonElement;

import android.app.Activity;
import android.content.Context;
import android.content.DialogInterface;
import android.content.Intent;
import android.media.AudioManager;
import android.os.AsyncTask;
import android.os.Bundle;
import android.speech.RecognizerIntent;
import android.speech.tts.*;
import android.text.TextUtils;
import android.util.Log;
import android.view.View;
import android.view.ViewGroup;
import android.widget.AdapterView;
import android.widget.Toast;

import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import ai.api.AIServiceException;
import ai.api.RequestExtras;
import ai.api.android.AIConfiguration;
import ai.api.android.AIDataService;
import ai.api.android.AIService;
import ai.api.model.AIContext;
import ai.api.model.AIError;
import ai.api.model.AIEvent;
import ai.api.model.AIRequest;
import ai.api.model.AIResponse;
import ai.api.model.Metadata;
import ai.api.model.Result;
import ai.api.model.Status;
import ai.api.ui.AIDialog;

/**
 * An {@link Activity} showing a tuggable "Hello World!" card.
 * <p>
 * The main content view is composed of a one-card {@link CardScrollView} that provides tugging
 * feedback to the user when swipe gestures are detected.
 * If your Glassware intends to intercept swipe gestures, you should set the content view directly
 * and use a {@link com.google.android.glass.touchpad.GestureDetector}.
 *
 * @see <a href="https://developers.google.com/glass/develop/gdk/touch">GDK Developer Guide</a>
 */
//public class MainActivity extends Activity  implements AIDialog.AIDialogListener{
public class MainActivity extends Activity {

    private static final String TAG ="Check here please" ;
    /**
     * {@link CardScrollView} to use as the main content view.
     */
    private CardScrollView mCardScroller;

    /**
     * "Hello World!" {@link View} generated by {@link #buildView()}.
     */
    private View mView, mView1;

    View cardView;

    private AIResponse response;

    ArrayList<String> voiceResults;

    private AIDialog aiDialog;

    private AIDataService aiDataservice;

    private String output="No output";
//    Context context=null;
    @Override
    protected void onCreate(Bundle bundle) {
        super.onCreate(bundle);


        final AIConfiguration config = new AIConfiguration("f78b059316b4419d9ccb23578aa50625",
                AIConfiguration.SupportedLanguages.English,
                AIConfiguration.RecognitionEngine.System);

        aiDataservice=new AIDataService(this,config);

        //task.execute("How is all machine working?","great");

        //aiRequest.setQuery("Hello");


        //aiDialog = new AIDialog(this, config);
        //aiDialog.setResultsListener(this);

        AndroidTextToSpeech t=new AndroidTextToSpeech(getApplicationContext());
        t.speak("Welcome to Ricktam Application");
        mView = buildView();
        //mView1 = buildView1();

        mCardScroller = new CardScrollView(this);
        mCardScroller.setAdapter(new CardScrollAdapter() {
            @Override
            public int getCount() {
                return 1;
            }

            @Override
            public Object getItem(int position) {
                return mView;
            }

            @Override
            public View getView(int position, View convertView, ViewGroup parent) {
                return mView;
            }

           @Override
            public int getPosition(Object item) {
                if (mView.equals(item)) {
                   return 0;
               }

               if (mView.equals(item)) {
                   return 1;
               }
                return AdapterView.INVALID_POSITION;
            }
        });
        // Handle the TAP event.
        mCardScroller.setOnItemClickListener(new AdapterView.OnItemClickListener() {
            @Override
            public void onItemClick(AdapterView<?> parent, View view, int position, long id) {
                // Plays disallowed sound to indicate that TAP actions are not supported.
                Toast.makeText(getApplicationContext(), output,Toast.LENGTH_LONG).show();
//                AudioManager am = (AudioManager) getSystemService(Context.AUDIO_SERVICE);
//                am.playSoundEffect(Sounds.DISALLOWED);
                aiDialog.showAndListen();

            }
        });
        setContentView(mCardScroller);





        //Intent intent = new Intent("com.google.zxing.client.android.SCAN");
        //intent.putExtra("SCAN_MODE", "QR_CODE_MODE");
        //startActivityForResult(intent, 0);

        aiDialog = new AIDialog(this, config);
        aiDialog.setResultsListener(new AIDialog.AIDialogListener(){


            @Override
            public void onResult(final AIResponse aiResponse) {
                // TODO Process aiResponse
                //aiDialog.close();
                Toast.makeText(getApplicationContext(), String.format("%s %s -- %s","Successful response: ",
                        aiResponse.getResult().getResolvedQuery(), aiResponse.getResult().getFulfillment().getSpeech()), Toast.LENGTH_LONG).show();
                AndroidTextToSpeech t=new AndroidTextToSpeech(getApplicationContext());
                t.speak(aiResponse.getResult().getFulfillment().getSpeech().toString());
                //MainActivity.this.finish();

            }

            @Override
            public void onError(final AIError aiError) {
                // TODO show error message
                //aiDialog.close();
                Toast.makeText(getApplicationContext(), aiError.getMessage(), Toast.LENGTH_SHORT).show();
                MainActivity.this.finish();
            }

            @Override
            public void onCancelled() {
                //aiDialog.close();
                Toast.makeText(getApplicationContext(), "Process cancelled", Toast.LENGTH_SHORT).show();
                //MainActivity.this.finish();
            }
        });

        aiDialog.getDialog().setOnDismissListener(new DialogInterface.OnDismissListener() {
            @Override
            public void onDismiss(final DialogInterface dialog) {
                Toast.makeText(getApplicationContext(), "Dialog dismissed by user", Toast.LENGTH_SHORT).show();
                //MainActivity.this.finish();
            }
        });
    }

    @Override
    protected void onResume() {
        super.onResume();

        /*if (aiDialog != null) {
            aiDialog.resume();
        }*/

        mCardScroller.activate();

//        aiDialog.showAndListen();
    }

    @Override
    protected void onPause() {
        mCardScroller.deactivate();

       /* if (aiDialog != null) {
            aiDialog.pause();
        }*/

        super.onPause();
    }

    /**
     * Builds a Glass styled "Hello World!" view using the {@link CardBuilder} class.
     */

    private View buildView()
    {

        View view1 = new CardBuilder(this, CardBuilder.Layout.CAPTION)
                .setText("The caption layout.")
                .setFootnote("This is the footnote")
                .setTimestamp("just now")
                .addImage(R.drawable.image)
                .getView();

        return view1;
    }

//For text message sending
    /*final AsyncTask<String, Void, AIResponse> task = new AsyncTask<String, Void, AIResponse>() {
        private AIError aiError;

        @Override
        protected AIResponse doInBackground(final String... params) {
            //final AIRequest request = requests[0];
            final AIRequest aiRequest = new AIRequest();
            String query = params[0];
            //String event = params[1];

            if (!TextUtils.isEmpty(query))
                aiRequest.setQuery(query);
           // if (!TextUtils.isEmpty(event))
            //    aiRequest.setEvent(new AIEvent(event));
            final String contextString = params[1];
            RequestExtras requestExtras = null;
            if (!TextUtils.isEmpty(contextString)) {
                final List<AIContext> contexts = Collections.singletonList(new AIContext(contextString));
                requestExtras = new RequestExtras(contexts, null);
            }
            try {
               response = aiDataservice.request(aiRequest,requestExtras);
                //resp = aiDataservice.getAIService().textRequest(text[0], new RequestExtras());
                return response;
            } catch (AIServiceException e) {

                aiError = new AIError(e);
                return null;
            }
            //return null;
        }
        @Override
        protected void onPostExecute(AIResponse aiResponse) {
            if (aiResponse != null) {
                onTextResult(aiResponse);
            } else {
                onTextError(aiError);
            }
        }


    };

    private void onTextResult(final AIResponse response) {
        runOnUiThread(new Runnable() {
            @Override
            public void run() {
                Log.d(TAG, "onResult");

                //resultTextView.setText(gson.toJson(response));

                Log.i(TAG, "Received success response");

                // this is example how to get different parts of result object
                final Status status = response.getStatus();
                Log.i(TAG, "Status code: " + status.getCode());
                Log.i(TAG, "Status type: " + status.getErrorType());

                final Result result = response.getResult();
                Log.i(TAG, "Resolved query: " + result.getResolvedQuery());

                Log.i(TAG, "Action: " + result.getAction());

                final String speech = result.getFulfillment().getSpeech();
                Log.i(TAG, "Speech: " + speech);
                //AndroidTextToSpeech.speak(speech);
                output=speech;

                Toast.makeText(getApplicationContext(), output,Toast.LENGTH_LONG).show();
                final Metadata metadata = result.getMetadata();
                if (metadata != null) {
                    Log.i(TAG, "Intent id: " + metadata.getIntentId());
                    Log.i(TAG, "Intent name: " + metadata.getIntentName());
                }

                final HashMap<String, JsonElement> params = result.getParameters();
                if (params != null && !params.isEmpty()) {
                    Log.i(TAG, "Parameters: ");
                    for (final Map.Entry<String, JsonElement> entry : params.entrySet()) {
                        Log.i(TAG, String.format("%s: %s", entry.getKey(), entry.getValue().toString()));
                    }
                }
            }

        });
    }

    private void onTextError(final AIError error) {
        runOnUiThread(new Runnable() {
            @Override
            public void run() {
               // resultTextView.setText(error.toString());
            }
        });
    }*/

// For voice

    /*@Override
    public void onResult(final AIResponse response) {
    runOnUiThread(new Runnable() {
        @Override
        public void run() {
            Log.d(TAG, "onResult");

            //resultTextView.setText(gson.toJson(response));

            Log.i(TAG, "Received success response");

            // this is example how to get different parts of result object
            final Status status = response.getStatus();
            Log.i(TAG, "Status code: " + status.getCode());
            Log.i(TAG, "Status type: " + status.getErrorType());

            final Result result = response.getResult();
            Log.i(TAG, "Resolved query: " + result.getResolvedQuery());

            Log.i(TAG, "Action: " + result.getAction());
            final String speech = result.getFulfillment().getSpeech();
            Log.i(TAG, "Speech: " + speech);
           // TTS.speak(speech);
            Toast.makeText(getApplicationContext(), speech,Toast.LENGTH_LONG).show();
            final Metadata metadata = result.getMetadata();
            if (metadata != null) {
                Log.i(TAG, "Intent id: " + metadata.getIntentId());
                Log.i(TAG, "Intent name: " + metadata.getIntentName());
            }

            final HashMap<String, JsonElement> params = result.getParameters();
            if (params != null && !params.isEmpty()) {
                Log.i(TAG, "Parameters: ");
                for (final Map.Entry<String, JsonElement> entry : params.entrySet()) {
                    Log.i(TAG, String.format("%s: %s", entry.getKey(), entry.getValue().toString()));
                }
            }
        }

    });
}

    @Override
    public void onError(final AIError error) {
        runOnUiThread(new Runnable() {
            @Override
            public void run() {
                //resultTextView.setText(error.toString());
            }
        });
    }

    @Override
    public void onCancelled() {
        runOnUiThread(new Runnable() {
            @Override
            public void run() {
                //resultTextView.setText("");
            }
        });
    }

*/


}
